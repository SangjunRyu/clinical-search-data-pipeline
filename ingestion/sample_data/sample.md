해당 디렉터리는 원본 데이터 및 프로젝트를 위해 데이터 가공을 처리하기 위해 사용했던 파이썬 파일과, 이를 통해 변환된 데이터의 일부이다.

session_based_mapping.py: 전체 데이터의 최소/최대 timestamp를 계산하여 데이터를 분할하고 처리함.

session_based_splitter.py: kafka 브로커에 데이터 적재를 session_id기준으로 하기 위해서, 그리고 가정이 웹서버쪽으로 들어오는 로그 트래픽은 l4 switch에서 session 기반으로 loadbalancing되었다고 가정했기에 이를 위해 데이터를 분배하기 위해 작성한 처리코드.

sort.py: 변환된 데이터가 timestamp순으로 구성되도록 데이터를 좀더 현실감 있게 적재된 것으로 만들기 위해 작성한 가공코드.

time_compression.py: 원래 가지고 있던 데이터가 2013-01-01부터 2020-10-30일 까지의 약 8년치 데이터였으나 이를 2026-01-01 ~ 2026-02-01까지의 데이터로, 각 일자별 데이터는 15~16시에 데이터 피크로서 트래픽이 집중되었다는 상황을 가정하기 위해 데이터 가공을 위해 작성한 코드
